FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535520000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464480000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=9 8 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (0, 0, 0.00000000000000000000e+000) (8, 4, 5.00000000000000000000e-001) (8, 4, 5.00000000000000000000e-001) (8, 4, 5.00000000000000000000e-001) (0, 0, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -9.22851543873548510000e-003) (1, 2.83142086118459700000e-002) (2, 8.44848677515983580000e-002) (3, 8.40881392359733580000e-002) (4, 5.73974624276161190000e-002) (5, 9.16931182146072390000e-002) (6, 1.43432617187500000000e-002) (7, 5.27343759313225750000e-003) (8, -5.04943840205669400000e-002) (0, 8.47717300057411190000e-002) (1, -8.20678696036338810000e-002) (2, -2.70507819950580600000e-002) (3, 3.02429199218750000000e-002) (4, 3.38134765625000000000e-002) (5, 6.93176314234733580000e-002) (6, 6.46362314000725750000e-003) (7, 1.70898437500000000000e-002) (8, -4.00939956307411190000e-002) (0, -1.53686525300145150000e-002) (1, -8.07922407984733580000e-002) (2, 8.44360366463661190000e-002) (3, -3.73535160906612870000e-003) (4, -4.81567392125725750000e-003) (5, 2.44079586118459700000e-002) (6, 7.11792036890983580000e-002) (7, -9.68627911061048510000e-003) (8, -3.38073745369911190000e-002) (0, 3.82690434344112870000e-003) (1, -2.68554693320766090000e-004) (2, -2.82043460756540300000e-002) (3, 1.75476074218750000000e-002) (4, -2.94494628906250000000e-002) (5, 1.25732421875000000000e-002) (6, -3.19030769169330600000e-002) (7, 2.72827153094112870000e-003) (8, 5.72143569588661190000e-002) (0, -6.74194321036338810000e-002) (1, -5.18676750361919400000e-002) (2, 2.19116220250725750000e-003) (3, -3.91540527343750000000e-002) (4, -4.64599616825580600000e-002) (5, -2.40112300962209700000e-002) (6, -1.25671392306685450000e-002) (7, -2.43835449218750000000e-002) (8, 6.68823271989822390000e-002) (0, -4.44213859736919400000e-002) (1, -8.79333540797233580000e-002) (2, -5.53039573132991790000e-002) (3, -6.89270049333572390000e-002) (4, 4.75463867187500000000e-002) (5, -1.39526370912790300000e-002) (6, 6.25427290797233580000e-002) (7, -1.02111818268895150000e-002) (8, -6.02844245731830600000e-002) (0, -1.06262210756540300000e-002) (1, -4.11926284432411190000e-002) (2, -5.48156760632991790000e-002) (3, 5.22827170789241790000e-002) (4, -1.85363776981830600000e-002) (5, -4.85229492187500000000e-003) (6, -7.51342764124274250000e-003) (7, 5.90271018445491790000e-002) (8, 6.25427290797233580000e-002) (9, 6.14013662561774250000e-003) (10, -7.78320357203483580000e-002) (11, 5.81054715439677240000e-003) (12, -5.68115226924419400000e-002) (13, 1.56494136899709700000e-002) (14, 9.59594771265983580000e-002) (15, 7.56835937500000000000e-003) (16, -2.16796882450580600000e-002) (9, -4.02221679687500000000e-002) (10, 2.90527357719838620000e-003) (11, 5.04760770127177240000e-003) (12, 2.19238288700580600000e-002) (13, -5.22583015263080600000e-002) (14, 1.78833014797419310000e-003) (15, -3.73718254268169400000e-002) (16, -4.12597656250000000000e-002) (9, 9.18701216578483580000e-002) (10, -4.38781753182411190000e-002) (11, -1.16760255768895150000e-002) (12, 6.90795928239822390000e-002) (13, 3.79943847656250000000e-002) (14, -3.20617668330669400000e-002) (15, -4.26208488643169400000e-002) (16, 8.31970199942588810000e-002) 
